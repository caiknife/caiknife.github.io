<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 缓存 | CDEFGAB 1010110]]></title>
  <link href="http://caiknife.github.io/blog/categories/huan-cun/atom.xml" rel="self"/>
  <link href="http://caiknife.github.io/"/>
  <updated>2019-02-21T13:20:57+08:00</updated>
  <id>http://caiknife.github.io/</id>
  <author>
    <name><![CDATA[CaiKnife]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[单线程redis为什么这么快？]]></title>
    <link href="http://caiknife.github.io/blog/2019/02/16/dan-xian-cheng-rediswei-shi-yao-zhe-yao-kuai/"/>
    <updated>2019-02-16T15:47:07+08:00</updated>
    <id>http://caiknife.github.io/blog/2019/02/16/dan-xian-cheng-rediswei-shi-yao-zhe-yao-kuai</id>
    <content type="html"><![CDATA[<p>redis 采用的是基于内存的采用的是单进程单线程模型的 KV 数据库，由 C 语言编写，官方提供的数据是可以达到 100000+ 的 QPS。这个数据不比采用单进程多线程的同样基于内存的 KV 数据库 Memcached 差。</p>

<p>有兴趣的可以参考官方的基准程序测试《How fast is Redis？》<a href="https://redis.io/topics/benchmarks">https://redis.io/topics/benchmarks</a></p>

<p><a href="/downloads/image/redis/benchmark.png" title="redis benchmark " class="fancybox"><img src="/downloads/image/redis/benchmark.png" alt="redis benchmark " /></a></p>

<!-- more -->


<p>Redis快的主要原因是：</p>

<blockquote><p>完全基于内存</p>

<p>数据结构简单，对数据操作也简单</p>

<p>使用多路 I/O 复用模型</p></blockquote>

<p>下面主要围绕第三点采用多路 I/O 复用技术来展开。</p>

<p>多路 I/O 复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络IO的时间消耗），且Redis在内存中操作数据的速度非常快（内存内的操作不会成为这里的性能瓶颈），主要以上两点造就了 redis 具有很高的吞吐量。</p>

<p>和 Memcached 不同，redis 并没有直接使用 libevent，而是自己完成了一个非常轻量级的对 select、epoll、evport、kqueue 这些通用的接口的实现。在不同的系统调用选用适合的接口，linux 下默认是 epoll。因为 libevent 比较重更通用代码量也就很庞大，拥有很多 redis 用不上的功能，redis为了追求“轻巧”并且去除依赖，就选择自己去封装了一套。</p>

<p>至于为什么 redis 要使用单进程单线程：</p>

<blockquote><p>代码更清晰，处理逻辑更简单</p>

<p>不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗</p>

<p>不存在多进程或者多线程导致的切换而消耗CPU</p></blockquote>

<p>至于弊端，那也是显而易见的——无法发挥多核 CPU 性能，不过可以通过在单机开多个 redis 实例来完善。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[数据延迟的情况下如何解决缓存脏数据]]></title>
    <link href="http://caiknife.github.io/blog/2018/11/27/huan-cun-shuang-tao-tai/"/>
    <updated>2018-11-27T21:24:20+08:00</updated>
    <id>http://caiknife.github.io/blog/2018/11/27/huan-cun-shuang-tao-tai</id>
    <content type="html"><![CDATA[<p>通常使用缓存的情况下，如果先删缓存，再更新数据库，有这样一个场景：</p>

<blockquote><p>单库情况下，服务层在进行长时间的逻辑计算，在这个过程中，可能读到旧数据入缓存。</p>

<p>主从库+读写分离情况下，在主从同步延时过程中，可能读到旧数据入缓存。</p></blockquote>

<!-- more -->


<p><strong><em>第一个问题产生的原因可能是同时有一个请求A进行更新操作，另一个请求B进行查询操作，那么可能会出现下面的情况：</em></strong></p>

<p><code>
请求A进行写操作，删除缓存
请求B查询发现缓存不存在
请求B去数据库查询得到旧值
请求B将旧值写入缓存
请求A将新值写入数据库
</code></p>

<p><strong><em>第二个问题产生的原因可能是，还是两个请求，一个请求A进行更新操作，另一个请求B进行查询操作，可能会出现下面的情况：</em></strong></p>

<p><code>
请求A进行写操作，删除缓存
请求A将数据写入数据库了
请求B查询缓存发现，缓存没有值
请求B去从库查询，这时，还没有完成主从同步，因此查询到的是旧值
请求B将旧值写入缓存
数据库完成主从同步，从库变为新值
</code></p>

<p>上面的这两种情况，都可以使用在写操作更新数据库之后，休眠一小段时间之后第二次再删除缓存。休眠的时间根据系统评估下来的写入时间或者是主从数据库的延迟时间上再加上几百毫秒即可。这样在增加一次cache miss的前提下，只花费了很少的成本，就避免了脏数据的长时间存在，保障了数据一致性。</p>

<p>而如果你并不想因为这个休眠时间导致影响到用户体验的话，其实可以使用异步的方式，通过队列来进行第二次删除，在队列里进行这段时间的休眠，从而保证用户体验，加大系统的吞吐量。</p>

<p><strong><em>如果在第二次删除缓存时失败了怎么办？</em></strong></p>

<p>假设有一个请求A进行更新操作，另一个请求B进行查询操作，为了方便，假设是单库：</p>

<p><code>
请求A进行写操作，删除缓存
请求B查询发现缓存不存在
请求B去数据库查询得到旧值
请求B将旧值写入缓存
请求A将新值写入数据库
请求A试图去删除请求B写入的缓存值，结果失败了
</code></p>

<p>即如果第二次删除缓存失败，会再次出现缓存和数据库不一致的问题。这种情况下，可以往队列中插入要删除的缓存key，在队列中处理删除缓存直到成功为止，如果可以接受的话，这未尝不是一种可行的解决方案。</p>

<p>暂时先想到这么多，如果有更好的解决方案，我会继续更新。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[聊聊 Memcache]]></title>
    <link href="http://caiknife.github.io/blog/2013/12/02/something-about-memcache/"/>
    <updated>2013-12-02T09:28:28+08:00</updated>
    <id>http://caiknife.github.io/blog/2013/12/02/something-about-memcache</id>
    <content type="html"><![CDATA[<h2>什么是 Memcache</h2>

<p>Memcached 是一个免费开源的、高性能的、具有分布式内存对象的缓存系统，它通过减轻数据库负载加速动态 Web 应用。最初版本由 LiveJournal 的 Brad Fitzpatrick 在 2003 年开发完成。目前全世界很多用户都在使用它来构建自己的大负载网站或提高自己的高访问网站的响应速度。Memcache 是这个项目的名称，而 Memcached 是服务器端的主程序文件名。</p>

<!-- more -->


<p>缓存一般用来保存一些经常存取的对象或数据（例如，浏览器会把经常访问的网页缓存起来），通过缓存来存取对象或数据要比磁盘存取快很多。Memcache 是一种内存缓存，把经常存取的对象或数据缓存在内存中，内存中缓存的这些数据通过 API 的方式被存取，数据就像一张大的 hash 表，以 key-value 对的方式存在。Memcache 通过缓存经常被存取的对象或数据，来减轻数据库的压力，提高网站的响应速度，构建速度更快的可扩展的Web应用。</p>

<p>Memcache 是一个分布式的缓存系统，既然是分布式的，那么就会碰到帽子定理（CAP theorem）。</p>

<h2>什么是 CAP theorem？</h2>

<p>在理论计算机科学中，CAP 定理（CAP theorem），又被称作布鲁尔定理（Brewer&rsquo;s theorem），它指出对于一个分布式计算系统来说，不可能同时满足以下三点：</p>

<pre><code>一致性（Consistency)（所有节点在同一时间具有相同的数据）

可用性（Availability）（保证每个请求不管成功或者失败都有响应）

分隔容忍（Partition tolerance）（系统中任意信息的丢失或失败不会影响系统的继续运作）
</code></pre>

<p>根据定理，分布式系统只能满足三项中的两项而不可能满足全部三项。所以，小伙伴们就不要冒着头发掉光的危险去想办法实现系统中的完美功能了，因为世界上就没有完美的东西。</p>

<h2>分布式 Memcache</h2>

<p>Memcache 在 PHP 下有两个扩展，分别是 <code>memcache</code> 和 <code>memcached</code>，由于之前在工作中一直都是用到 <code>memcache</code> ，因此下面的内容将以这个扩展为准。</p>

<p>Memcache 的 PHP 扩展在客户端实现了分布式功能，通过很简单的代码就能添加或者减少节点，比如：</p>

<p><code>php
&lt;?php
$memcache = new Memcache();
$memcache-&gt;addServer('memcache_host', 11211);
$memcache-&gt;addServer('memcache_host2', 11211);
// ...coding to add more memcache servers...
</code></p>

<p>而 Memcache 选取节点的算法，一般情况下是采用取余算法，通过 <code>crc32</code> 函数将 key 处理之后的结果对当前节点数目进行取余，取余的结果就决定这条 key 将会映射到哪个节点上。不过这样一来就会有一个很明显的问题——如果在生产环境上增加或者减少节点，那么在做取余运算的时候，原有的 key 几乎都要映射到新的节点上，原有的缓存基本都生效了。在服务器遇到极大访问量的时候，压力就会直接到达数据库，啊多么痛的领悟！！！</p>

<p>于是就有了改进的分布式算法——<code>一致性 hash 算法</code>。</p>

<h2>一致性 hash 算法</h2>

<p>分布式缓存设计核心点：在设计分布式 cache 系统的时候，我们需要让 key 的分布均衡，并且在增加 cache server 后，cache 的迁移做到最少。一致性哈希算法的做法是：选择具体的机器节点不在只依赖需要缓存数据的 key 的哈希本身了，而是机器节点本身也进行了哈希运算。</p>

<h3>hash 机器节点</h3>

<p>首先求出机器节点的 hash 值，然后将其分布到0～2<sup>32</sup>的一个圆环上（顺时针分布）。如下图所示：</p>

<p><a href="/downloads/image/memcache/1.gif" title="图 – 1 " class="fancybox"><img src="/downloads/image/memcache/1.gif" alt="图 – 1 " /></a></p>

<p>集群中有机器：A , B, C, D, E 五台机器，通过一定的 hash 算法我们将其分布到如上图所示的环上。</p>

<h3>访问方式</h3>

<p>如果有一个写入缓存的请求，其中 key 值为 K，计算其 hash 值 Hash(K)， Hash(K) 对应于图 – 1环中的某一个点，如果该点对应没有映射到具体的某一个机器节点，那么顺时针查找，直到第一次找到有映射机器的节点，该节点就是确定的目标节点，如果超过了 2<sup>32</sup> 仍然找不到节点，则命中第一个机器节点。比如 Hash(K) 的值介于 A ~ B 之间，那么命中的机器节点应该是 B 节点（如上图）。</p>

<h3>增加节点的处理</h3>

<p>如上图 – 1，在原有集群的基础上欲增加一台机器 F，增加过程如下：</p>

<p>计算机器节点的 hash值，将机器映射到环中的一个节点，如下图：</p>

<p><a href="/downloads/image/memcache/2.gif" title="图 – 2 " class="fancybox"><img src="/downloads/image/memcache/2.gif" alt="图 – 2 " /></a></p>

<p>增加机器节点 F 之后，访问策略不改变，依然按照之前方式访问，此时缓存命不中的情况依然不可避免，不能命中的数据是 hash(K)在增加节点以前落在 C～F 之间的数据。尽管依然存在节点增加带来的命中问题，但是比较传统的 hash 取模的方式，一致性 hash 已经将不命中的数据降到了最低。</p>

<p>一致性哈希算法最大限度地抑制了 hash 键的重新分布。另外要取得比较好的负载均衡的效果，往往在服务器数量比较少的时候需要增加虚拟节点来保证服务器能均匀的分布在圆环上。因为使用一般的 hash 方法，服务器的映射地点的分布非常不均匀。使用虚拟节点的思想，为每个物理节点（服务器）在圆上分配 100～200 个点。这样就能抑制分布不均匀，最大限度地减小服务器增减时的缓存重新分布。用户数据映射在虚拟节点上，就表示用户数据真正存储位置是在该虚拟节点代表的实际物理服务器上。下面有一个图描述了需要为每台物理服务器增加的虚拟节点。</p>

<p><a href="/downloads/image/memcache/3.gif" title="图 – 3 " class="fancybox"><img src="/downloads/image/memcache/3.gif" alt="图 – 3 " /></a></p>

<p>X 轴表示的是需要为每台物理服务器扩展的虚拟节点倍数(scale)，Y 轴是实际物理服务器数，可以看出，当物理服务器的数量很小时，需要更大的虚拟节点，反之则需要更少的节点。从图上可以看出，在物理服务器有 10 台时，差不多需要为每台服务器增加 100 ~ 200 个虚拟节点才能达到真正的负载均衡。</p>

<h2>Memcache 的小知识</h2>

<p>1、单条缓存值限制为 1 MB。</p>

<p>2、key 的限制为 250 Bytes。</p>

<p>3、cache 失效算法是 LRU 算法。</p>

<p>4、cache 默认失效时间和最长缓存时间都是 30 天。</p>

<h2>参考链接</h2>

<p><a href="http://zh.wikipedia.org/wiki/Memcached">http://zh.wikipedia.org/wiki/Memcached</a><br/>
<a href="http://zh.wikipedia.org/wiki/CAP%E5%AE%9A%E7%90%86">http://zh.wikipedia.org/wiki/CAP%E5%AE%9A%E7%90%86</a><br/>
<a href="http://zh.wikipedia.org/wiki/%E5%BF%AB%E5%8F%96%E6%96%87%E4%BB%B6%E7%BD%AE%E6%8F%9B%E6%A9%9F%E5%88%B6">http://zh.wikipedia.org/wiki/%E5%BF%AB%E5%8F%96%E6%96%87%E4%BB%B6%E7%BD%AE%E6%8F%9B%E6%A9%9F%E5%88%B6</a><br/>
<a href="http://zh.wikipedia.org/wiki/%E5%BE%AA%E7%8E%AF%E5%86%97%E4%BD%99%E6%A0%A1%E9%AA%8C">http://zh.wikipedia.org/wiki/%E5%BE%AA%E7%8E%AF%E5%86%97%E4%BD%99%E6%A0%A1%E9%AA%8C</a><br/>
<a href="http://us1.php.net/manual/zh/book.memcache.php">http://us1.php.net/manual/zh/book.memcache.php</a>
<a href="http://php.net/manual/zh/book.memcached.php">http://php.net/manual/zh/book.memcached.php</a></p>

<p>Have a nice day！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何处理 Dog Pile Effect]]></title>
    <link href="http://caiknife.github.io/blog/2013/11/20/how-to-deal-with-dog-pile-effect/"/>
    <updated>2013-11-20T16:02:00+08:00</updated>
    <id>http://caiknife.github.io/blog/2013/11/20/how-to-deal-with-dog-pile-effect</id>
    <content type="html"><![CDATA[<p>什么是 Dog Pile Effect？</p>

<p>在缓存系统中，缓存总有失效的时候，比如我们经常使用的 Memcache 和 Redis ，都会设置超时时间；而一旦缓存到了超时时间失效之后，如果此时再有大量的并发向数据库发起请求，就会造成服务器卡顿甚至是系统当机。这就是 Dog Pile Effect 。</p>

<!-- more -->


<p><a href="/downloads/image/dog-pile/dog-pile.png" title="Dog Pile Effect " class="fancybox"><img src="/downloads/image/dog-pile/dog-pile.png" alt="Dog Pile Effect " /></a></p>

<p>参考下面的代码：</p>

<p>``` php
&lt;?php
$mc = new Memcached();
$mc->addServers(array(</p>

<pre><code>array('127.0.0.1', 11211, 40),
array('127.0.0.1', 11212, 30),
array('127.0.0.1', 11213, 30)
</code></pre>

<p>));
$data = $mc->get(&lsquo;cached_key&rsquo;);
if ($mc->getResultCode() === Memcached::RES_NOTFOUND) {</p>

<pre><code>$data = generateData(); // long-running process
$mc-&gt;set('cached_key', $data, time() + 30);
</code></pre>

<p>}
var_dump($data);
```</p>

<p>如果第 10 行代码需要执行 1 秒钟，而这个时间上正好缓存失效，系统又正好碰到访问高峰，比如 1000 RPS ，这样在生成缓存之前，所有的请求都会直接访问到数据库服务器上，导致系统故障。</p>

<p>避免这样的 Dog Pile 效应，通常有两种方法：</p>

<h3>使用独立的更新进程</h3>

<p>使用独立的进程（比如 cron job）去更新缓存，而不是让 web 服务器即时更新数据缓存。举个例子：一个数据统计需要每五分钟更新一次（但是每次计算过程耗时1分钟），那么可以使用 cron job 去计算这个数据，并更新缓存。这样的话，数据永远都会存在，即使不存在也不用担心产生 Dog Pile 效应，因为客户端没有更新缓存的操作。这种方法适合不需要即时运算的全局数据。但对用户对象、朋友列表、评论之类的就不太适用。</p>

<h3>使用“锁”</h3>

<p>除了使用独立的更新进程之外，我们也可以通过加“锁”，每次只允许一个客户端请求去更新缓存，以避免 Dog Pile 效应。</p>

<p>处理过程大概是这样的：</p>

<p>A 请求的缓存没命中<br/>
A 请求“锁住”缓存 key<br/>
B 请求的缓存没命中<br/>
B 请求需要等待直到“锁”释放<br/>
A 请求完成，并且释放“锁”<br/>
B 请求缓存命中（由于 A 的运算）</p>

<p>下面的代码就用到“锁”来处理：</p>

<p>``` php
&lt;?php
function get($key) {</p>

<pre><code>$mc = new Memcached();
$mc-&gt;addServers(array(
    array('127.0.0.1', 11211, 40),
    array('127.0.0.1', 11212, 30),
    array('127.0.0.1', 11213, 30)
));
$data = $mc-&gt;get($key);
// check if cache exists
if ($mc-&gt;getResultCode() === Memcached::RES_SUCCESS) {
    return $data;
}

// add locking
$mc-&gt;add('lock:' . $key, 'locked', 20);
if ($mc-&gt;getResultCode() === Memcached::RES_SUCCESS) {
    $data = generateData();
    $mc-&gt;set($key, $data, 30);
} else {
    while(1) {
        usleep(500000);
        $data = $mc-&gt;get($key);
        if ($data !== false){
            break;
        }
    }
}
return $data;
</code></pre>

<p>}</p>

<p>$data = get(&lsquo;cached_key&rsquo;);</p>

<p>var_dump($data);
```</p>

<p>打完收工，Have a nice day！</p>
]]></content>
  </entry>
  
</feed>
