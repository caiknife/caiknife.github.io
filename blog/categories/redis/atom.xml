<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: redis | 但行好事，莫问前程]]></title>
  <link href="http://caiknife.github.io/blog/categories/redis/atom.xml" rel="self"/>
  <link href="http://caiknife.github.io/"/>
  <updated>2018-11-30T19:59:17+08:00</updated>
  <id>http://caiknife.github.io/</id>
  <author>
    <name><![CDATA[CaiKnife]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[使用redis实现分布式锁]]></title>
    <link href="http://caiknife.github.io/blog/2018/11/30/shi-yong-redisshi-xian-fen-bu-shi-suo/"/>
    <updated>2018-11-30T19:03:54+08:00</updated>
    <id>http://caiknife.github.io/blog/2018/11/30/shi-yong-redisshi-xian-fen-bu-shi-suo</id>
    <content type="html"><![CDATA[<p>redis除了是很强大的存储/缓存工具之外，还可以实现分布式锁。</p>

<p>下面我们来看看到底怎么样用redis来实现分布式锁。</p>

<!-- more -->


<h3>为什么要使用锁？</h3>

<p>第一个是正确性，这个众人皆知。就像Java里的synchronize，就是用来保证多线程并发场景下，程序的正确性。在redis的场合下，并发访问的单位，不再是线程，而是进程。</p>

<p>举个例子，一个文件系统，为了提高性能，部署了三台文件服务器。当服务器A在修改文件A的时候，其他服务器就不能对文件A进行修改，否则A的修改就会被覆盖掉。</p>

<p>锁还有第二个用处——效率。比如应用A有一个耗时的统计任务，每天凌晨两点，定时执行，这时我们给应用A部署了三台机器，如果不加锁，那么每天凌晨两点一到，这三台机器就都会去执行这个很耗时的统计任务，而实际上，我们最后只需要一份统计结果。</p>

<p>这时候，就可以在定时任务开始前，先去获取锁，获取到锁的，执行统计任务，获取不到的，就直接结束。</p>

<h3>分布式锁和本地锁的区别是什么？</h3>

<p>单机，并发的单位是线程，分布式，并发的单位是多进程。并发单位的等级上去了，锁的等级自然也得上去。以前锁是进程自己的，进程下的线程都看这个锁的眼色行事，谁拿到锁，谁才可以放行。进程外面还有别的进程，你要跟别人合作，就不能光看着自己了，得有一个大家都看得到的，光明正大的地方，来放这把锁。</p>

<h3>获取锁</h3>

<p>要怎么在redis里获取一把锁呢？貌似很简单，执行set命令就好了，还是上面文件系统的例子，比如你想修改文件id是9527的文件，那就往redis里，添加一个key为file:9527，value为任意字符串的值即可：</p>

<p><code>
set file:9527 ${random_value}
</code></p>

<p>set成功了，就说明获取到锁。</p>

<p>这样可以吗？很明显不行，set方法默认是会覆盖的，也就是说，就算file:9527已经有值了，set还是可以成功，这样锁就起不到互斥的作用。</p>

<p>那在set之前，先用get判断一下，如果是null，再去set？也不行，原因很简单，get和set都在客户端执行，不具有原子性。</p>

<p>要实现原子性，唯一的办法，就是只给redis发送一条命令，来完成获取锁的动作。</p>

<p>于是就有了下面这条命令：</p>

<p><code>
set file:9527 ${random_value} NX
</code></p>

<p>NX = If Not Existed 如果不存在，才执行set。</p>

<p>完美了吗？非也，这个值没有设置过期时间，如果后面获得锁的客户端，因为挂掉了，或者其他原因，没有释放锁，那其他进程也都获取不到锁了，结果就是死锁。</p>

<p>所以有了终极版的获取锁命令：</p>

<p><code>
set file:9527 ${random_value} NX EX ${timeout}
</code></p>

<p>使用EX参数，可以设置过期时间，单位是秒，另一个参数PX，也可以设置过期时间，单位是毫秒。</p>

<h3>释放锁</h3>

<p>好，最后再来看看释放锁。</p>

<p>有人说，释放锁，简单，直接del：</p>

<p><code>
del file:9527
</code></p>

<p>有问题吗？当然有，这会把别人的锁给释放掉。</p>

<p>举个例子：</p>

<p><code>
A拿到了锁，过期时间5s
5s过去了，A还没释放锁，也许是发生了GC，也许是某个耗时操作
锁过期了，B抢到了锁
A缓过神来了，以为锁还是自己的，执行del file:9527
C抢到了锁，也进来了
B看看屋里的C，有看看刚出门的A，对着A吼了一句：尼玛，你干嘛把我的锁释放了
</code></p>

<p>所以，为了防止把别人的锁释放了，必须检查一下，当前的value是不是自己设置进去的value，如果不是，就说明锁不是自己的了，不能释放。</p>

<p>显然，这个过程，如果放在客户端做，就又不满足原子性了，只能整在一起，一次性让redis server执行完。</p>

<p>这下redis可没有一条命令，可以做这么多事情的，好在redis提供了lua脚本的调用方式，只需使用eval命令调用以下脚本即可：</p>

<p>```lua
if redis.call(&ldquo;get&rdquo;,KEYS[1]) == ARGV[1] then</p>

<pre><code>return redis.call("del",KEYS[1])
</code></pre>

<p>else</p>

<pre><code>return 0
</code></pre>

<p>end
```</p>

<h3>其实还有问题</h3>

<p>了解完如何释放锁，再加上之前的获取锁，我们似乎已经可以用redis来实现分布式锁了。</p>

<p>但是，一如既往，问自己一句，完美了吗？没有漏洞了？嗯，很明显不是，上面讲的算法，都有一个前提：只有一台redis实例。</p>

<p>而生产环境里，我们是不可能只部署一个实例的，至少，我们也是主从的架构。redis的数据同步，不是强一致性的，毕竟作为一个缓存，要保证读写性能。</p>

<p>如果A往Master放入了一把锁，然后再数据同步到Slave之前，Master crash，Slave被提拔为Master，这时候Master上面就没有锁了，这样其他进程也可以拿到锁，违法了锁的互斥性。</p>

<p>如何解决这个问题？</p>

<h3>Redlock算法</h3>

<p>针对Redis集群架构，redis的作者antirez提出了Redlock算法，来实现集群架构下的分布式锁。</p>

<p>Redlock算法并不复杂，我们先简单描述一下，假设我们Redis分片下，有三个Master的节点，这三个Master，又各自有一个Slave。</p>

<p>好，现在客户端想获取一把分布式锁：</p>

<p><code>txt
记下开始获取锁的时间 startTime
按照A-&gt;B-&gt;C的顺序，依次向这三台Master发送获取锁的命令。客户端在等待每台Master回响应时，都有超时时间 timeout。举个例子，客户端向A发送获取锁的命令，在等了 timeout 时间之后，都没收到响应，就会认为获取锁失败，继续尝试获取下一把锁
如果获取到超过半数的锁，也就是 3/2+1 = 2把锁，这时候还没完，要记下当前时间 endTime
计算拿到这些锁花费的时间 costTime = endTime - startTime，如果costTime小于锁的过期时间 expireTime，则认为获取锁成功
如果获取不到超过一半的锁，或者拿到超过一半的锁时，计算出 costTime &gt;= expireTime，这两种情况下，都视为获取锁失败
如果获取锁失败，需要向全部Master节点，都发生释放锁的命令，也就是那段Lua脚本
</code></p>

<p>当然这个Redlock算法也并不是万能的，也会有缺陷，我也在思考在哪些场景下会有这样的问题。但是在目前绝大情况下来说，Redlock已经足够用了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何处理 Dog Pile Effect]]></title>
    <link href="http://caiknife.github.io/blog/2013/11/20/how-to-deal-with-dog-pile-effect/"/>
    <updated>2013-11-20T16:02:00+08:00</updated>
    <id>http://caiknife.github.io/blog/2013/11/20/how-to-deal-with-dog-pile-effect</id>
    <content type="html"><![CDATA[<p>什么是 Dog Pile Effect？</p>

<p>在缓存系统中，缓存总有失效的时候，比如我们经常使用的 Memcache 和 Redis ，都会设置超时时间；而一旦缓存到了超时时间失效之后，如果此时再有大量的并发向数据库发起请求，就会造成服务器卡顿甚至是系统当机。这就是 Dog Pile Effect 。</p>

<!-- more -->


<p>{% fancybox /downloads/image/dog-pile/dog-pile.png Dog Pile Effect %}</p>

<p>参考下面的代码：</p>

<p>``` php
&lt;?php
$mc = new Memcached();
$mc->addServers(array(</p>

<pre><code>array('127.0.0.1', 11211, 40),
array('127.0.0.1', 11212, 30),
array('127.0.0.1', 11213, 30)
</code></pre>

<p>));
$data = $mc->get(&lsquo;cached_key&rsquo;);
if ($mc->getResultCode() === Memcached::RES_NOTFOUND) {</p>

<pre><code>$data = generateData(); // long-running process
$mc-&gt;set('cached_key', $data, time() + 30);
</code></pre>

<p>}
var_dump($data);
```</p>

<p>如果第 10 行代码需要执行 1 秒钟，而这个时间上正好缓存失效，系统又正好碰到访问高峰，比如 1000 RPS ，这样在生成缓存之前，所有的请求都会直接访问到数据库服务器上，导致系统故障。</p>

<p>避免这样的 Dog Pile 效应，通常有两种方法：</p>

<h3>使用独立的更新进程</h3>

<p>使用独立的进程（比如 cron job）去更新缓存，而不是让 web 服务器即时更新数据缓存。举个例子：一个数据统计需要每五分钟更新一次（但是每次计算过程耗时1分钟），那么可以使用 cron job 去计算这个数据，并更新缓存。这样的话，数据永远都会存在，即使不存在也不用担心产生 Dog Pile 效应，因为客户端没有更新缓存的操作。这种方法适合不需要即时运算的全局数据。但对用户对象、朋友列表、评论之类的就不太适用。</p>

<h3>使用“锁”</h3>

<p>除了使用独立的更新进程之外，我们也可以通过加“锁”，每次只允许一个客户端请求去更新缓存，以避免 Dog Pile 效应。</p>

<p>处理过程大概是这样的：</p>

<p>A 请求的缓存没命中<br/>
A 请求“锁住”缓存 key<br/>
B 请求的缓存没命中<br/>
B 请求需要等待直到“锁”释放<br/>
A 请求完成，并且释放“锁”<br/>
B 请求缓存命中（由于 A 的运算）</p>

<p>下面的代码就用到“锁”来处理：</p>

<p>``` php
&lt;?php
function get($key) {</p>

<pre><code>$mc = new Memcached();
$mc-&gt;addServers(array(
    array('127.0.0.1', 11211, 40),
    array('127.0.0.1', 11212, 30),
    array('127.0.0.1', 11213, 30)
));
$data = $mc-&gt;get($key);
// check if cache exists
if ($mc-&gt;getResultCode() === Memcached::RES_SUCCESS) {
    return $data;
}

// add locking
$mc-&gt;add('lock:' . $key, 'locked', 20);
if ($mc-&gt;getResultCode() === Memcached::RES_SUCCESS) {
    $data = generateData();
    $mc-&gt;set($key, $data, 30);
} else {
    while(1) {
        usleep(500000);
        $data = $mc-&gt;get($key);
        if ($data !== false){
            break;
        }
    }
}
return $data;
</code></pre>

<p>}</p>

<p>$data = get(&lsquo;cached_key&rsquo;);</p>

<p>var_dump($data);
```</p>

<p>打完收工，Have a nice day！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[发现了 redis commander 的一个 bug]]></title>
    <link href="http://caiknife.github.io/blog/2013/09/18/redis-commander-bug/"/>
    <updated>2013-09-18T21:45:00+08:00</updated>
    <id>http://caiknife.github.io/blog/2013/09/18/redis-commander-bug</id>
    <content type="html"><![CDATA[<p>长久以来，我的工作平台是 Ubuntu ，而我用来管理 redis 的工具是 <a href="http://nearinfinity.github.io/redis-commander/">redis-commander</a>。</p>

<p>之前我由于做了 redis 的主从备份，开启了本地的 6379 端口和 6380 端口作为 redis 的两个实例，前者作为主机，后者是从机。并且在 redis-commander 的管理界面上分别添加了 6379 和 6380 的 0 号数据库。后来为了提高机器的性能，我关闭了 6380 的实例，并删除了这个实例在 redis-commander 的 tree-view 中对应的分支。结果后来再进入 redis-commander 的时候，左边的实例管理 tree-view 消失了，检查控制台输出时，发现提示是无法连接到 6380 端口。</p>

<p><strong>为什么我已经删掉了对应的分支，但是 redis-commander 还是会请求 6380 端口呢？</strong></p>

<!-- more -->


<p>首先想到了可能是 redis-commander 的配置文件有问题。于是我从 redis-commander 的源代码入手去检查。</p>

<p>在 <code>/usr/lib/node_modules/redis-commander/lib/util.js</code> 这个文件下找到了 redis-commander 的配置文件路径：</p>

<p>``` js+php
//Config Util functions
exports.getConfig = function (callback) {
  fs.readFile(getUserHome() + &ldquo;/.redis-commander&rdquo;, &lsquo;utf8&rsquo;, function (err, data) {</p>

<pre><code>if (err) {
  callback(err);
} else {
  var config = JSON.parse(data);
  callback(null, config);
}
</code></pre>

<p>  });
};</p>

<p>exports.saveConfig = function (config, callback) {
  fs.writeFile(getUserHome() + &ldquo;/.redis-commander&rdquo;, JSON.stringify(config), function (err) {</p>

<pre><code>if (err) {
  callback(err);
} else {
  callback(null);
}
</code></pre>

<p>  });
};
```</p>

<p>于是修改 <code>/home/caiknife/.redis-commander</code> 这个文件的内容：</p>

<p>``` js+php
{</p>

<pre><code>"sidebarWidth":"454",
"locked":"true",
"CLIHeight":"94",
"CLIOpen":"false",
"default_connections":[
    {"host":"localhost","port":"6379","password":"","dbIndex":"0"},
    {"host":"localhost","port":"6379","password":"","dbIndex":"1"},
    {"host":"localhost","port":"6380","password":"","dbIndex":"0"}
]
</code></pre>

<p>}
```</p>

<p>很明显，虽然我删除了一个连接，但是配置文件中并没有更新这个删除操作，仍然保留了以前的内容。所以我得手动删除。</p>

<p>于是删除多余的配置，重新启动 redis-commander 。 OK ，一切又正常了。</p>

<p>Have a nice day！</p>

<p><strong>2013年9月19日更新</strong></p>

<p>删除实例的时候在控制台里看到 <code>Could not remove localhost:6379:1 from default connections.</code> ，然后在 <code>/usr/lib/node_modules/redis-commander/lib/routes/home.js</code> 找到了对应的源代码：</p>

<p>``` js+php
function removeConnectionFromDefaults (connections, connectionIds, callback) {
  var notRemoved = true;
  var hostname = connectionIds[0];
  var port = connectionIds[1];
  var db = connectionIds[2];
  connections.forEach(function (connection, index) {</p>

<pre><code>console.log(connection.selected_db);
console.log(connection);
if (notRemoved &amp;&amp; connection.host == hostname &amp;&amp; connection.port == port &amp;&amp; connection.selected_db == db) {
  notRemoved = false;
  connections.splice(index, 1);
}
</code></pre>

<p>  });
  if (notRemoved) {</p>

<pre><code>return callback("Could not remove " + hostname + ":" + port + ":" + db + " from default connections.");
</code></pre>

<p>  } else {</p>

<pre><code>return callback(null, connections);
</code></pre>

<p>  }
}
```</p>

<p>通过 <code>console.log(connection.selected_db);</code> 发现始终返回 <code>undefined</code> 。接着输出 <code>console.log(connection);</code> 发现它是一个这样的数据结构：</p>

<p><code>js+php
{ host: 'localhost', port: '6379', password: '', dbIndex: '2' }
</code></p>

<p>可见这里有个 bug ，在应该使用 <code>dbIndex</code> 的地方使用了 <code>selected_db</code> 。修改代码后就可以正常删除连接实例并更新到配置文件里了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[redis实验（1）]]></title>
    <link href="http://caiknife.github.io/blog/2013/08/20/redis-experiment/"/>
    <updated>2013-08-20T21:30:00+08:00</updated>
    <id>http://caiknife.github.io/blog/2013/08/20/redis-experiment</id>
    <content type="html"><![CDATA[<p>研究了一下redis的常用技巧。</p>

<p>除了SET方法之外，redis还有MSET方法可以批量设置，如果发现有同名的key存在，就会覆盖原有的key。如果不想覆盖已经存在的key，请使用MSETNX方法。</p>

<p>用法：MSET key value [key value &hellip;]<br/>
<code>
redis&gt; MSET key1 "Hello" key2 "World"
OK
redis&gt; GET key1
"Hello"
redis&gt; GET key2
"World"
redis&gt;
</code></p>

<p>用法：MSETNX key value [key value &hellip;]<br/>
<code>
redis&gt; MSETNX key1 "Hello" key2 "there"
(integer) 1
redis&gt; MSETNX key2 "there" key3 "world"
(integer) 0
redis&gt; MGET key1 key2 key3
1) "Hello"
2) "there"
3) (nil)
redis&gt;
</code></p>

<!-- more -->


<p>查讯key就要使用KEYS方法，文档中提到KEYS方法速度很快，虽然时间复杂度是O(N)，但是在一台入门级的笔记本电脑上，搜索100W条key，redis只需要40毫秒左右。但是在生产环境上，还是尽量不要使用KEYS命令，而是使用set来进行查询。</p>

<blockquote><p><strong><em>Warning</em></strong>: consider KEYS as a command that should only be used in production environments with extreme care. It may ruin performance when it is executed against large databases. This command is intended for debugging and special operations, such as changing your keyspace layout. Don&rsquo;t use KEYS in your regular application code. If you&rsquo;re looking for a way to find keys in a subset of your keyspace, consider using sets.</p></blockquote>

<p>用法：KEYS pattern <br/>
<code>
redis&gt; MSET one 1 two 2 three 3 four 4
OK
redis&gt; KEYS *o*
1) "two"
2) "one"
3) "four"
redis&gt; KEYS t??
1) "two"
redis&gt; KEYS *
1) "two"
2) "three"
3) "one"
4) "four"
redis&gt;
</code></p>

<p>在redis里，排序是一件比较复杂的事情，<a href="http://redis.io/commands/sort">官方文档写得很详细</a> 。</p>

<p>用法：SORT key [BY pattern] [LIMIT offset count] [GET pattern [GET pattern &hellip;]] [ASC|DESC] [ALPHA] [STORE destination]。正常排序还是很好理解的，直接<code>SORT key LIMIT offset count ASC|DESC ALPHA</code>即可，<code>LIMIT</code>和SQL语句中的含义一样，一般用来做分页用；<code>ASC|DESC</code>就是升序/降序排列；<code>ALPHA</code>表示将元素都当作字符串对待。</p>

<p>不过在使用外部key进行排序的时候，就有点复杂了。</p>

<p>举个例子，<code>SORT mylist BY weight_* GET object_*</code>。首先就要求你在mylist中存储是所有weight_*的id，而这句话的意思就是根据weight进行升序排序，并获得对应的id，并由此获得对应的排序完成的object值。用SQL来描述就是：<code>SELECT object FROM table ORDER BY weight ASC;</code>。同样还有用hashes来进行排序的——<code>SORT mylist BY weight_*-&gt;fieldname GET object_*-&gt;fieldname</code>，这就好比<code>SELECT b.fielname FROM weight a LEFT JOIN object b ON a.id=b.id ORDER BY a.fieldname ASC;</code>。更详细的内容，还是参考<a href="http://redis.io/commands/sort">文档</a> 。</p>

<p>下面是一部分测试代码，里面有更详细的注释。</p>

<p>{% include_code redis-py/demo.py %}</p>

<p>Have a nice day！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[redis主从复制]]></title>
    <link href="http://caiknife.github.io/blog/2013/08/13/redis-replication/"/>
    <updated>2013-08-13T23:54:00+08:00</updated>
    <id>http://caiknife.github.io/blog/2013/08/13/redis-replication</id>
    <content type="html"><![CDATA[<p>晚上在家尝试做了一下redis的主从复制。下面的Linux命令有一部分需要sudo才能完成。</p>

<p>首先复制一份redis.conf：</p>

<p><code>bash
$ cp /etc/redis/redis.conf /etc/redis/slave.conf
</code></p>

<p>有几处地方需要修改：</p>

<p>``` bash
$ vi /etc/redis/slave.conf</p>

<p>port 6380
logfile /var/log/redis/redis-server-slave.log
dbfilename slave.rdb
slaveof 127.0.0.1 6379
```</p>

<!-- more -->


<p>设置开机启动：</p>

<p><code>bash
$ cp /etc/init.d/redis-server /etc/init.d/redis-server-slave
</code></p>

<p>修改启动项：</p>

<p>{% include_code redis-replication/redis-server-slave %}</p>

<p>最后执行：</p>

<p><code>bash
$ service redis-server-slave start
</code></p>

<p>最后确认同步是否成功：</p>

<p><code>bash
$ cd /var/lib/redis
$ md5sum *.rdb
</code></p>

<p>如果checksum值是相同的，则表示同步成功。</p>

<p>把redis-server-slave设置为开机启动：</p>

<p><code>bash
$ update-rc.d redis-server-slave defaults
</code></p>

<p>如果要取消开机启动：</p>

<p><code>bash
$ update-rc.d -f redis-server-slave remove
</code></p>

<p>配置文件redis.conf里有一部分和save相关的参数，缺省如下：</p>

<p>``` bash</p>

<h1>Save the DB on disk:</h1>

<p>#</p>

<h1>save <seconds> <changes></h1>

<p>#</p>

<h1>Will save the DB if both the given number of seconds and the given</h1>

<h1>number of write operations against the DB occurred.</h1>

<p>#</p>

<h1>In the example below the behaviour will be to save:</h1>

<h1>after 900 sec (15 min) if at least 1 key changed</h1>

<h1>after 300 sec (5 min) if at least 10 keys changed</h1>

<h1>after 60 sec if at least 10000 keys changed</h1>

<p>save 900 1
save 300 10
save 60 10000
```</p>

<p>在主服务器上，我们可以去掉上面的设置，改成类似下面的设置（只要参数值够大即可）：</p>

<p><code>bash
save 10000000000 10000000000
</code></p>

<p>如此一来主服务器变成一个完全的内存服务器，所有的操作都在内存里完成，“永远”不会再往磁盘上持久化保存数据，异步的也没有。持久化则通过从服务器来完成，这样在操作主服务器的时候效率会更高。不过要注意的一点是此方法不适合保存关键数据，否则一旦主服务器挂掉，如果你头脑一热简单的重启服务，那么从服务器的数据也会跟着消失，此时，必须拷贝一份备份数据到主服务器，然后再重启服务才可以，数据的恢复稍显麻烦。</p>

<p>从服务器也可以通过设置这个参数来调整从内存同步到磁盘的频率。</p>

<p>Have a nice day！</p>
]]></content>
  </entry>
  
</feed>
